{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Programming for Data Science - DS-GA 1007</span>\n",
    "## <span style=\"color:blue\">Lecture 12: Pandas - Part III</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "- Pivot Tables\n",
    "- Grouping, Aggregation and Transformation\n",
    "\n",
    "__References__<br>\n",
    "- [Pandas: powerful Python data analysis toolkit: Wes McKinney & PyData Devel. Team](https://pandas.pydata.org/pandas-docs/stable/pandas.pdf)\n",
    "- [http://pandas.pydata.org/pandas-docs/stable/index.html](http://pandas.pydata.org/pandas-docs/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy\n",
    "Group operations using split-apply-combine pipeline.\n",
    "- Split a pandas object into groups based on one or more keys from rows (axis=0) or columns (axis=1)\n",
    "- A function is applied to each group\n",
    "- The result of the function is combined into a new object\n",
    "\n",
    "__PS__: Groups are represented by a GroupBy object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{ccccc}\n",
    "DataFrame & & Split & Apply & Combine\\\\\n",
    "\\begin{array}{c|c}\n",
    "C1 & C2 \\\\ \\hline\n",
    "A & 0 \\\\ \\hline\n",
    "B & 5 \\\\ \\hline\n",
    "C & 10 \\\\ \\hline\n",
    "A & 5 \\\\ \\hline\n",
    "B & 5 \\\\ \\hline\n",
    "C & 10 \\\\ \\hline\n",
    "A & 10 \\\\ \\hline\n",
    "B & 5 \\\\ \\hline\n",
    "C & 10 \n",
    "\\end{array} &\n",
    "\\begin{array}{c}\n",
    "\\nearrow \\\\ \\\\\n",
    "\\rightarrow \\\\ \\\\\n",
    "\\searrow\n",
    "\\end{array} &\n",
    "\\begin{array}{c|c}\n",
    "A & 0 \\\\ \\hline\n",
    "A & 5 \\\\ \\hline\n",
    "A & 10 \\\\ \\\\\n",
    "B & 5 \\\\ \\hline\n",
    "B & 5 \\\\ \\hline\n",
    "B & 5 \\\\ \\\\\n",
    "C & 10 \\\\ \\hline\n",
    "C & 10 \\\\ \\hline\n",
    "C & 10 \n",
    "\\end{array} &\n",
    "\\begin{array}{c}\n",
    "\\searrow\\\\ \\\\\n",
    "\\rightarrow \\\\ \\\\\n",
    "\\nearrow\n",
    "\\end{array} & \n",
    "\\begin{array}{c|c}\n",
    "A & 15 \\\\ \\hline\n",
    "B & 15 \\\\ \\hline\n",
    "C & 30 \n",
    "\\end{array}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The splitting ''keys'' do not have to be of the same type\n",
    "  - A list or array of values that is the same length as the axis being grouped\n",
    "  - A value indicating a column name in a DataFrame\n",
    "  - A dict or Series providing a mapping between values on the axis being grouped and the group names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key1 key2     data1     data2\n",
      "0    a  one  0.579327  0.840200\n",
      "1    a  two  0.798034  0.291710\n",
      "2    b  one  0.931207  0.125801\n",
      "3    b  two  0.264197  0.175929\n",
      "4    a  one  0.234048  0.965384\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame({'key1': ['a','a','b','b','a'],\n",
    "                  'key2': ['one','two','one','two','one'], \n",
    "                  'data1': np.random.uniform(low=0,high=1,size=5),\n",
    "                  'data2': np.random.uniform(low=0,high=1,size=5)})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key1\n",
      "a    0.537136\n",
      "b    0.597702\n",
      "Name: data1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "gb1 = df['data1'].groupby(df['key1'])  \n",
    "print(gb1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.groupby.generic.SeriesGroupBy'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# groupby results in a groupby object\n",
    "# but the final combination/aggregation is a dataframe or series\n",
    "\n",
    "print(type(gb1))\n",
    "print(type(gb1.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      data1     data2\n",
      "0  0.579327  0.125801\n",
      "1  0.234048  0.175929\n"
     ]
    }
   ],
   "source": [
    "# using a list as keys (same lenght) as the dataframe\n",
    "external_list = [0,1,0,1,1]\n",
    "bg2 = df[['data1','data2']].groupby(external_list)\n",
    "print(bg2.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PS__: Multimple ''keys'' result in a hierarchical index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              data1     data2\n",
      "key1 key2                    \n",
      "a    one   0.579327  0.965384\n",
      "     two   0.798034  0.291710\n",
      "b    one   0.931207  0.125801\n",
      "     two   0.264197  0.175929\n"
     ]
    }
   ],
   "source": [
    "bg3 = df[['data1','data2']].groupby([df['key1'],df['key2']])\n",
    "print(bg3.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating Over Groups\n",
    "The `groupby` method generates a squence of 2-tuples containing group _name_ and _data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      data1     data2 key1 key2\n",
      "0  0.050465  0.472563    a  one\n",
      "1  0.835403  0.408942    a  two\n",
      "2  0.712161  0.255194    b  one\n",
      "3  0.834593  0.361111    b  two\n",
      "4  0.370471  0.483622    a  one\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'key1': ['a','a','b','b','a'],\n",
    "                  'key2': ['one','two','one','two','one'], \n",
    "                  'data1': np.random.uniform(low=0,high=1,size=5),\n",
    "                  'data2': np.random.uniform(low=0,high=1,size=5)})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "      data1     data2\n",
      "0  0.050465  0.472563\n",
      "1  0.835403  0.408942\n",
      "4  0.370471  0.483622\n",
      "b\n",
      "      data1     data2\n",
      "2  0.712161  0.255194\n",
      "3  0.834593  0.361111\n",
      "-----\n",
      "('a', 'one')\n",
      "      data1     data2\n",
      "0  0.050465  0.472563\n",
      "4  0.370471  0.483622 <class 'pandas.core.frame.DataFrame'>\n",
      "('a', 'two')\n",
      "      data1     data2\n",
      "1  0.835403  0.408942 <class 'pandas.core.frame.DataFrame'>\n",
      "('b', 'one')\n",
      "      data1     data2\n",
      "2  0.712161  0.255194 <class 'pandas.core.frame.DataFrame'>\n",
      "('b', 'two')\n",
      "      data1     data2\n",
      "3  0.834593  0.361111 <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "bg2 = df[['data1','data2']].groupby(df['key1'])\n",
    "\n",
    "for name, group in bg2:\n",
    "    print(name)\n",
    "    print(group)\n",
    "    \n",
    "print(5*'-')\n",
    "bg3 = df[['data1','data2']].groupby([df['key1'],df['key2']])\n",
    "for name, group in bg3:\n",
    "    print(name)\n",
    "    print(group,type(group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping with dictionaries\n",
    "Combines columns using a dictionary mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        a  b  c  d  e\n",
      "Joe     1  6  8  4  0\n",
      "Steve   4  4  3  6  2\n",
      "Wes     1  8  9  9  5\n",
      "Jim     0  0  7  0  2\n",
      "Travis  0  7  7  5  1\n"
     ]
    }
   ],
   "source": [
    "dfp = pd.DataFrame(data=np.random.randint(low=0, high=10, size=(5,5)),\n",
    "               columns=['a','b','c','d','e'], \n",
    "               index=['Joe','Steve','Wes','Jim','Travis'])\n",
    "print(dfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue\n",
      "        c  d\n",
      "Joe     8  4\n",
      "Steve   3  6\n",
      "Wes     9  9\n",
      "Jim     7  0\n",
      "Travis  7  5\n",
      "red\n",
      "        a  b  e\n",
      "Joe     1  6  0\n",
      "Steve   4  4  2\n",
      "Wes     1  8  5\n",
      "Jim     0  0  2\n",
      "Travis  0  7  1\n",
      "        blue  red\n",
      "Joe       12    7\n",
      "Steve      9   10\n",
      "Wes       18   14\n",
      "Jim        7    2\n",
      "Travis    12    8\n"
     ]
    }
   ],
   "source": [
    "mapping = {'a':'red', 'b':'red', 'c':'blue',\n",
    "           'd':'blue', 'e':'red', 'f':'orange'}\n",
    "\n",
    "gbd = dfp.groupby(mapping, axis=1)\n",
    "\n",
    "for name, group in gbd:\n",
    "    print(name)\n",
    "    print(group)\n",
    "\n",
    "print(gbd.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping with functions\n",
    "- A function passed as a group key will be called once per __index__ value\n",
    "- The return value is used as the group name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        a  b  c  d  e\n",
      "Joe     4  3  6  7  9\n",
      "Steve   9  4  6  4  0\n",
      "Wes     4  8  2  0  5\n",
      "Jim     7  8  2  9  4\n",
      "Travis  9  0  4  7  1\n",
      "3\n",
      "     a  b  c  d  e\n",
      "Joe  4  3  6  7  9\n",
      "Wes  4  8  2  0  5\n",
      "Jim  7  8  2  9  4\n",
      "5\n",
      "       a  b  c  d  e\n",
      "Steve  9  4  6  4  0\n",
      "6\n",
      "        a  b  c  d  e\n",
      "Travis  9  0  4  7  1\n"
     ]
    }
   ],
   "source": [
    "dfp = pd.DataFrame(data=np.random.randint(low=0, high=10, size=(5,5)),\n",
    "               columns=['a','b','c','d','e'], \n",
    "               index=['Joe','Steve','Wes','Jim','Travis'])\n",
    "print(dfp)\n",
    "\n",
    "gbf = dfp.groupby(lambda x: len(x))\n",
    "\n",
    "for name,group in gbf:\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform\n",
    "- The `transform` method applies function to each group\n",
    "- The result is placed in the appropriate locations\n",
    "- The function must return a scalar or a transformed array of the same size as the group\n",
    "- If each group produces a scalar value, it will be broadcasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        a  b  c  d  e\n",
      "Joe     2  4  2  3  5\n",
      "Steve   9  2  1  2  5\n",
      "Wes     9  0  8  2  1\n",
      "Jim     5  7  1  0  7\n",
      "Travis  5  4  5  2  4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dfp = pd.DataFrame(data=np.random.randint(low=0, high=10, size=(5,5)),\n",
    "               columns=['a','b','c','d','e'], \n",
    "               index=['Joe','Steve','Wes','Jim','Travis'])\n",
    "print(dfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "        a  b  c  d  e\n",
      "Joe     2  4  2  3  5\n",
      "Wes     9  0  8  2  1\n",
      "Travis  5  4  5  2  4\n",
      "**********\n",
      "two\n",
      "       a  b  c  d  e\n",
      "Steve  9  2  1  2  5\n",
      "Jim    5  7  1  0  7\n",
      "**********\n",
      "-----\n",
      "     a  b  c  d  e\n",
      "one  9  4  8  3  5\n",
      "two  9  7  1  2  7\n",
      "-----\n",
      "        a  b  c  d  e\n",
      "Joe     9  4  8  3  5\n",
      "Steve   9  7  1  2  7\n",
      "Wes     9  4  8  3  5\n",
      "Jim     9  7  1  2  7\n",
      "Travis  9  4  8  3  5\n"
     ]
    }
   ],
   "source": [
    "key=['one','two','one','two','one']\n",
    "\n",
    "gbm = dfp.groupby(key)\n",
    "\n",
    "for n,g in gbm:\n",
    "    print(n)\n",
    "    print(g)\n",
    "    print(5*'**')\n",
    "\n",
    "print(5*'-')\n",
    "# max aggregation \n",
    "print(gbm.max())\n",
    "\n",
    "print(5*'-')\n",
    "# max via transform \n",
    "print(gbm.transform(np.max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply\n",
    "Most general GroupBy method\n",
    "- Splits the object into pieces\n",
    "- Invokes the supplied function on each piece\n",
    "- Concatenates the pieces together again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        a  b  c  d  e\n",
      "Joe     9  6  7  1  4\n",
      "Steve   7  3  8  9  1\n",
      "Wes     9  2  9  9  1\n",
      "Jim     4  8  5  0  6\n",
      "Travis  9  6  3  4  8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dfp = pd.DataFrame(data=np.random.randint(low=0, high=10, size=(5,5)),\n",
    "               columns=['a','b','c','d','e'], \n",
    "               index=['Joe','Steve','Wes','Jim','Travis'])\n",
    "print(dfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "one\n",
      "        a  b  c  d  e\n",
      "Joe     9  6  7  1  4\n",
      "Wes     9  2  9  9  1\n",
      "Travis  9  6  3  4  8\n",
      "-----\n",
      "two\n",
      "       a  b  c  d  e\n",
      "Steve  7  3  8  9  1\n",
      "Jim    4  8  5  0  6\n",
      "-----\n",
      "            a  b  c  d  e\n",
      "one Wes     9  2  9  9  1\n",
      "    Travis  9  6  3  4  8\n",
      "two Jim     4  8  5  0  6\n",
      "    Steve   7  3  8  9  1\n",
      "-----\n",
      "        a  b  c  d  e\n",
      "Wes     9  2  9  9  1\n",
      "Travis  9  6  3  4  8\n",
      "Jim     4  8  5  0  6\n",
      "Steve   7  3  8  9  1\n"
     ]
    }
   ],
   "source": [
    "def top2(df):\n",
    "    return(df.sort_values(by='a')[-2:])\n",
    "\n",
    "#print(dfp.sort_values(by='a')[-2:])\n",
    "\n",
    "print(5*'-')\n",
    "key=['one','two','one','two','one']\n",
    "dfpa = dfp.groupby(key)\n",
    "\n",
    "for n,g in dfpa:\n",
    "    print(n)\n",
    "    print(g)\n",
    "    print(5*'-')\n",
    "    \n",
    "print(dfpa.apply(top2))\n",
    "\n",
    "print(5*'-')\n",
    "print(dfp.groupby(key,group_keys=False).apply(top2)) # avoid hierarchical indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "Can use `groupby` to fill missing values with group-specific values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     c1   c2  c3  c4   c5\n",
      "0   5.0  9.0   2   9  9.0\n",
      "1   3.0  9.0   8   6  1.0\n",
      "2   5.0  1.0   8   9  9.0\n",
      "3   0.0  2.0   0   3  1.0\n",
      "4   4.0  2.0   9   3  9.0\n",
      "5   8.0  4.0   8   3  1.0\n",
      "6   NaN  NaN   2   0  NaN\n",
      "7   NaN  NaN   8   5  NaN\n",
      "8   NaN  NaN   3   1  NaN\n",
      "9   NaN  NaN   9   8  NaN\n",
      "10  0.0  8.0   1   3  1.0\n",
      "11  1.0  2.0   4   7  6.0\n",
      "12  9.0  3.0   4   2  1.0\n",
      "13  4.0  4.0   9   5  9.0\n",
      "14  8.0  0.0   9   5  4.0\n",
      "15  8.0  9.0   9   1  9.0\n",
      "16  1.0  7.0   6   8  0.0\n",
      "17  NaN  NaN   8   8  NaN\n",
      "18  5.0  9.0   6   3  5.0\n",
      "19  2.0  0.0   7   4  2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(data=np.random.randint(low=0, high=10, size=(20,5)),\n",
    "               columns=['c1','c2','c3','c4','c5'])\n",
    "\n",
    "r = np.random.randint(low=0, high=20, size=5)\n",
    "c = np.random.randint(low=0, high=5, size=5)\n",
    "df.iloc[r,c] = np.nan\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g1', 'g2', 'g1', 'g2', 'g3', 'g2', 'g3', 'g2', 'g2', 'g3', 'g1', 'g1', 'g1', 'g3', 'g2', 'g2', 'g2', 'g3', 'g1', 'g1']\n"
     ]
    }
   ],
   "source": [
    "# generating keys to group by\n",
    "keys = np.random.randint(low=0,high=3,size=20).tolist()\n",
    "dkeys = {0:'g1',1:'g2',2:'g3'}\n",
    "keys = [dkeys[i] for i in keys]\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          c1        c2  c3  c4        c5\n",
      "0   5.000000  9.000000   2   9  9.000000\n",
      "1   3.000000  9.000000   8   6  1.000000\n",
      "2   5.000000  1.000000   8   9  9.000000\n",
      "3   0.000000  2.000000   0   3  1.000000\n",
      "4   4.000000  2.000000   9   3  9.000000\n",
      "5   8.000000  4.000000   8   3  1.000000\n",
      "6   4.000000  3.000000   2   0  9.000000\n",
      "7   4.666667  5.166667   8   5  2.666667\n",
      "8   4.666667  5.166667   3   1  2.666667\n",
      "9   4.000000  3.000000   9   8  9.000000\n",
      "10  0.000000  8.000000   1   3  1.000000\n",
      "11  1.000000  2.000000   4   7  6.000000\n",
      "12  9.000000  3.000000   4   2  1.000000\n",
      "13  4.000000  4.000000   9   5  9.000000\n",
      "14  8.000000  0.000000   9   5  4.000000\n",
      "15  8.000000  9.000000   9   1  9.000000\n",
      "16  1.000000  7.000000   6   8  0.000000\n",
      "17  4.000000  3.000000   8   8  9.000000\n",
      "18  5.000000  9.000000   6   3  5.000000\n",
      "19  2.000000  0.000000   7   4  2.000000\n"
     ]
    }
   ],
   "source": [
    "# filling nans in each group with the mean of the group\n",
    "dfg = df.groupby(keys,group_keys=False)\n",
    "print(dfg.apply(lambda x: x.fillna(x.mean())).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot\n",
    "- Used to create a new derived table\n",
    "- Three arguments: index, columns, and values\n",
    "- Columns comes from original table\n",
    "\n",
    "`Pivot` creates a new table whose row and column indices are the unique values from the index and column parameters.\n",
    "- Cell values are taken from the column given as the values parameter\n",
    "- Multiple rows with same values might result in a ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Item   CType  USD  EU\n",
      "0  Item0    gold    2   1\n",
      "1  Item0  bronze    4   3\n",
      "2  Item1    gold    6   5\n",
      "3  Item1  silver    8   7\n",
      "4  Item0  silver   10   9\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'Item': ['Item0','Item0','Item1','Item1', 'Item0'],\n",
    "                      'CType': ['gold','bronze','gold','silver','silver'], \n",
    "                      'USD': [i for i in range(2,11,2)],\n",
    "                      'EU': [i for i in range(1,11,2)]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CType  bronze  gold  silver\n",
      "Item                       \n",
      "Item0     4.0   2.0    10.0\n",
      "Item1     NaN   6.0     8.0\n"
     ]
    }
   ],
   "source": [
    "df_pivot = df.pivot(index='Item', columns='CType',values='USD')\n",
    "print(df_pivot)\n",
    "# error because there are mutiple entries for one thing \n",
    "# fix by having the last gold to silver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PS__: If the `values` parameter is not provided then and hierarchical index is used to handle the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         USD                 EU            \n",
      "CType bronze gold silver bronze gold silver\n",
      "Item                                       \n",
      "Item0    4.0  2.0   10.0    3.0  1.0    9.0\n",
      "Item1    NaN  6.0    8.0    NaN  5.0    7.0\n",
      "-----\n",
      "CType  bronze  gold  silver\n",
      "Item                       \n",
      "Item0     3.0   1.0     9.0\n",
      "Item1     NaN   5.0     7.0\n",
      "-----\n",
      "CType  bronze  gold  silver\n",
      "Item                       \n",
      "Item0     4.0   2.0    10.0\n",
      "Item1     NaN   6.0     8.0\n"
     ]
    }
   ],
   "source": [
    "df_pivot = df.pivot(index='Item', columns='CType')\n",
    "print(df_pivot)\n",
    "print(5*'-')\n",
    "print(df_pivot['EU'])\n",
    "print(5*'-')\n",
    "print(df_pivot['USD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Tables\n",
    "If rows have duplicate data, then `pivot` will raise a ValueError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Item   CType  USD  EU\n",
      "0  Item0    gold    2   1\n",
      "1  Item0  bronze    4   3\n",
      "2  Item1    gold    6   5\n",
      "3  Item1  silver    8   7\n",
      "4  Item0  silver   10   9\n",
      "5  Item0  silver   12  11\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'Item': ['Item0','Item0','Item1','Item1', 'Item0','Item0'],\n",
    "                      'CType': ['gold','bronze','gold','silver','silver','silver'], \n",
    "                      'USD': [i for i in range(2,13,2)],\n",
    "                      'EU': [i for i in range(1,13,2)]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ac01136ee29f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_pivot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Item'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'CType'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'USD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_pivot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/jupyterhub/2019-FA-DS-GA-1007/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m   5917\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5919\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5921\u001b[0m     _shared_docs[\n",
      "\u001b[0;32m/share/apps/jupyterhub/2019-FA-DS-GA-1007/lib/python3.7/site-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(data, index, columns, values)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mindexed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mindexed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/jupyterhub/2019-FA-DS-GA-1007/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(self, level, fill_value)\u001b[0m\n\u001b[1;32m   3743\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3745\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3747\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/jupyterhub/2019-FA-DS-GA-1007/lib/python3.7/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(obj, level, fill_value)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0mconstructor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_expanddim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         )\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munstacker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/jupyterhub/2019-FA-DS-GA-1007/lib/python3.7/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, index, level, value_columns, fill_value, constructor)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_sorted_values_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_selectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_sorted_values_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/jupyterhub/2019-FA-DS-GA-1007/lib/python3.7/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m_make_selectors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Index contains duplicate entries, \"\u001b[0m \u001b[0;34m\"cannot reshape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "df_pivot = df.pivot(index='Item', columns='CType',values='USD')\n",
    "print(df_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate values can be handled via `pivot_table` command, which aggregates values using a given aggregation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Item   CType  USD  EU\n",
      "0  Item0    gold    2   1\n",
      "1  Item0  bronze    4   3\n",
      "2  Item1    gold    6   5\n",
      "3  Item1  silver    8   7\n",
      "4  Item0    gold   10   9\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'Item': ['Item0','Item0','Item1','Item1', 'Item0'],\n",
    "                      'CType': ['gold','bronze','gold','silver','gold'], \n",
    "                      'USD': [i for i in range(2,11,2)],\n",
    "                      'EU': [i for i in range(1,11,2)]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CType  bronze  gold  silver\n",
      "Item                       \n",
      "Item0     4.0  12.0     NaN\n",
      "Item1     NaN   6.0     8.0\n"
     ]
    }
   ],
   "source": [
    "df_pivot = df.pivot_table(index='Item', columns='CType',values='USD',aggfunc=sum)\n",
    "print(df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
