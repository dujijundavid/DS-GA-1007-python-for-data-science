{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging, Validating, and Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFENSIVE PROGRAMMING\n",
    "\n",
    "- Write specifications for functions. Document assumptions and constraints\n",
    "- Break up the code into pieces programs\n",
    "- Check conditions on inputs/outputs (assertions)\n",
    "\n",
    "Testing/Validating is comparing Input/Output\n",
    "\n",
    "Debugging is studying what went wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Debugging\n",
    "\n",
    "Steps \n",
    "\n",
    "- print statements or logging \n",
    "- setting break points \n",
    "- bisection method like in Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "Remember that a prime number is only divisible by itself or 1. The following code to find primes has bugs...try to fix them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primes_list_buggy(n):\n",
    "   \"\"\"\n",
    "   input: n an integer > 1\n",
    "   returns: list of all the primes up to and including n\n",
    "   \"\"\"\n",
    "   # initialize primes list \n",
    "    pdb.set_trace()\n",
    "    if i == 2:\n",
    "        primes.append(2)\n",
    "   # go through each elem of primes list\n",
    "   for i in range(len(primes)):\n",
    "       # go through each of 2...n\n",
    "       for j in range(len(n)):\n",
    "           # check if not divisible by elem of list\n",
    "           if i%j != 0:\n",
    "                primes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primes_list_buggy(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FIXES: --------------------------\n",
    "## = invalid syntax, variable i unknown, variable primes unknown\n",
    "## can't apply 'len' to an int\n",
    "## division by zero -> iterate through elems not indices\n",
    "##                  -> iterate from 2 not 0\n",
    "## forgot to return \n",
    "## primes is empty list for n > 2\n",
    "## n = 3 goes through loop once -> range to n+1 not n\n",
    "## infinite loop -> append j not i\n",
    "##               -> list is getting modified as iterating over it!\n",
    "##               -> switch loops around\n",
    "## n = 4 adds 4 -> need way to stop going once found a divisible num\n",
    "##              -> use a flag\n",
    "## --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[2, 3, 5, 7, 11, 13]\n"
     ]
    }
   ],
   "source": [
    "def primes_list(n):\n",
    "    \"\"\"\n",
    "    input: n an integer > 1\n",
    "    returns: list of all the primes up to and including n\n",
    "    \"\"\"\n",
    "    # initialize primes list\n",
    "    primes = [2]\n",
    "    # go through each of 3...n\n",
    "    for j in range(3,n+1):\n",
    "        is_div = False\n",
    "        # go through each elem of primes list\n",
    "        for p in primes:\n",
    "            if j%p == 0:\n",
    "                is_div = True\n",
    "                #break\n",
    "        if not is_div:\n",
    "            primes.append(j)\n",
    "    return primes\n",
    "\n",
    "print(primes_list(2) )               \n",
    "print(primes_list(15)  )              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "The following code to reverse a list has bugs...try to fix them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "def rev_list_buggy(L):\n",
    "   \"\"\"\n",
    "   input: L, a list\n",
    "   Modifies L such that its elements are in reverse order\n",
    "   returns: nothing\n",
    "   \"\"\"\n",
    "   for i in range(int(len(L)/2)):\n",
    "       j = len(L) - i - 1\n",
    "       temp = L[i]\n",
    "       L[i] = L[j]\n",
    "       L[j] = temp\n",
    "\n",
    "L = [1,2,3,4]\n",
    "rev_list_buggy(L)\n",
    "print(L)      \n",
    "\n",
    "\n",
    "# or \n",
    "# L[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FIXES: --------------------------\n",
    "## temp unknown\n",
    "## list index out of range -> sub 1 to j\n",
    "## get same list back -> iterate only over half\n",
    "## --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rev_list(L):\n",
    "#     \"\"\"\n",
    "#     input: L, a list\n",
    "#     Modifies L such that its elements are in reverse order\n",
    "#     returns: nothing\n",
    "#     \"\"\"\n",
    "#     for i in range(len(L)//2):\n",
    "#         j = len(L) - i - 1\n",
    "#         temp = L[i]\n",
    "#         L[i] = L[j]\n",
    "#         L[j] = temp\n",
    "\n",
    "# L = [1,2,3,4]\n",
    "# rev_list(L)\n",
    "# print(L)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "The following includes error catching for arithmetic using try/except/finally statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "executed no matter what!\n",
      "success\n",
      "executed no matter what!\n",
      "[0.5, 1.0]\n"
     ]
    }
   ],
   "source": [
    "def get_ratios(L1, L2):\n",
    "    \"\"\" Assumes: L1 and L2 are lists of equal length of numbers\n",
    "        Returns: a list containing L1[i]/L2[i] \"\"\"\n",
    "    ratios = []\n",
    "    for index in range(len(L1)):\n",
    "        try:\n",
    "            ratios.append(L1[index]/L2[index])\n",
    "        except ZeroDivisionError:\n",
    "            ratios.append(float('nan')) #nan = Not a Number\n",
    "        except:\n",
    "            raise ValueError('get_ratios called with bad arg')\n",
    "        else:\n",
    "            print(\"success\")\n",
    "        finally:\n",
    "            print(\"executed no matter what!\")\n",
    "    return ratios\n",
    "    \n",
    "print(get_ratios([1, 4], [2, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4\n",
    "The following does not include error catching... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg function: version without an exception\n",
    "def avg(grades):\n",
    "   return (sum(grades))/len(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(class_list):\n",
    "\tnew_stats = []\n",
    "\tfor person in class_list:\n",
    "\t\tnew_stats.append([person[0], person[1], avg(person[1])])\n",
    "\treturn new_stats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following includes error catching for arithmetic using try/except/finally along with assert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg function: version with an exception\n",
    "def avg(grades):\n",
    "    try:\n",
    "        return sum(grades)/len(grades)\n",
    "    except ZeroDivisionError:\n",
    "        print('warning: no grades data')\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg function: version with assert\n",
    "def avg(grades):\n",
    "    assert len(grades) != 0, 'warning: no grades data'\n",
    "    return sum(grades)/len(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg function: version with raise\n",
    "def avg(grades):\n",
    "    if len(grades) != 0: \n",
    "        raise ZeroDivisionError('warning: no grades data')\n",
    "    return sum(grades)/len(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "warning: no grades data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-9e78fb048faf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m               [['laura', 'johnson'], []]]\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_grades\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-fca3899f6924>\u001b[0m in \u001b[0;36mget_stats\u001b[1;34m(class_list)\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[0mnew_stats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mperson\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclass_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                 \u001b[0mnew_stats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperson\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperson\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperson\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_stats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-b2bf86abdfe7>\u001b[0m in \u001b[0;36mavg\u001b[1;34m(grades)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrades\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrades\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'warning: no grades data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrades\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrades\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: warning: no grades data"
     ]
    }
   ],
   "source": [
    "test_grades = [[['john', 'smith'], [80.0, 70.0, 85.0]], \n",
    "              [['jane', 'doe'], [100.0, 80.0, 74.0]],\n",
    "              [['laura', 'johnson'], []]]\n",
    "\n",
    "print(get_stats(test_grades))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "The following does not check the user input. Try to add error catching to avoid problems with arithmetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me one number: 1\n",
      "Tell me another number: 2\n",
      "a/b =  0.5\n",
      "a+b =  3\n"
     ]
    }
   ],
   "source": [
    "a = int(input(\"Tell me one number: \"))\n",
    "b = int(input(\"Tell me another number: \"))\n",
    "print(\"a/b = \", a/b)\n",
    "print(\"a+b = \", a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of errors might you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     a = int(input(\"Tell me one number: \"))\n",
    "#     b = int(input(\"Tell me another number: \"))\n",
    "#     print(\"a/b = \", a/b)\n",
    "# except:\n",
    "#     print(\"Bug in user input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you try catching those errors separately?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     a = int(input(\"Tell me one number: \"))\n",
    "#     b = int(input(\"Tell me another number: \"))\n",
    "#     print(\"a/b = \", a/b)\n",
    "#     print(\"a+b = \", a+b)\n",
    "# except ValueError:\n",
    "#     print(\"Could not convert to a number.\")\n",
    "# except ZeroDivisionError:\n",
    "#     print(\"Can't divide by zero\")\n",
    "# except:\n",
    "#     print(\"Something went very wrong.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes of Tests\n",
    "\n",
    "#### Unit testing\n",
    " - validate each piece of program\n",
    " - testing each function separately\n",
    " \n",
    "#### Regression testing\n",
    " - add test for bugs as you find them\n",
    " - catch reintroduced errors that were previously fixed\n",
    "\n",
    "#### Integration testing\n",
    " - does overall program work?\n",
    " - tend to rush to do this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Testing\n",
    "\n",
    "#### Intuition\n",
    " - use the logic of the program\n",
    "\n",
    "#### Property Based Testing \n",
    " - stress test with high numbers, low numbers, ...\n",
    "\n",
    "#### Black Box\n",
    " - More reusable\n",
    "\n",
    "#### Glass Box\n",
    " - More thorough but harder to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - test fixture:\n",
    "A test fixture is used as a baseline for running tests to ensure that there is a fixed environment in which tests are run so that results are repeatable.\n",
    " - test case:\n",
    "A test case is a set of conditions which is used to determine whether a system under test works correctly.\n",
    " - test suite:\n",
    "Test suite is a collection of testcases that are used to test a software program to show that it has some specified set of behaviours by executing the aggregated tests together.\n",
    " - test runner:\n",
    "A test runner is a component which set up the execution of tests and provides the outcome to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5\n",
    "Summing numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_choice (__main__.TestSequenceFunctions) ... ok\n",
      "test_sample (__main__.TestSequenceFunctions) ... ok\n",
      "test_shuffle (__main__.TestSequenceFunctions) ... ERROR\n",
      "test_sum (__main__.TestSum) ... ok\n",
      "test_sum_tuple (__main__.TestSum) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_shuffle (__main__.TestSequenceFunctions)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-35-bd757b49fe10>\", line 8, in test_shuffle\n",
      "    random.shuffle(self.seq)\n",
      "  File \"C:\\Users\\policast\\Programs\\Anaconda3.7\\lib\\random.py\", line 278, in shuffle\n",
      "    x[i], x[j] = x[j], x[i]\n",
      "TypeError: 'range' object does not support item assignment\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_sum_tuple (__main__.TestSum)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-41-104fd55aeb27>\", line 7, in test_sum_tuple\n",
      "    self.assertEqual(sum((1, 2, 2)), 6, \"Should be 6\")\n",
      "AssertionError: 5 != 6 : Should be 6\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.017s\n",
      "\n",
      "FAILED (failures=1, errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x19234515278>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestSum(unittest.TestCase):\n",
    "\n",
    "    def test_sum(self):\n",
    "        self.assertEqual(sum([1, 2, 3]), 6, \"Should be 6\")\n",
    "\n",
    "    def test_sum_tuple(self):\n",
    "        self.assertEqual(sum((1, 2, 2)), 6, \"Should be 6\")\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - OK – This means that all the tests are passed.\n",
    " - FAIL – This means that the test did not pass and an AssertionError exception is raised.\n",
    " - ERROR – This means that the test raises an exception other than AssertionError."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6\n",
    "\n",
    "Randomly permuting numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_choice (__main__.TestSequenceFunctions) ... ok\n",
      "test_sample (__main__.TestSequenceFunctions) ... ok\n",
      "test_shuffle (__main__.TestSequenceFunctions) ... ERROR\n",
      "test_sum (__main__.TestSum) ... ok\n",
      "test_sum_tuple (__main__.TestSum) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_shuffle (__main__.TestSequenceFunctions)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-42-6f09b57bdf15>\", line 8, in test_shuffle\n",
      "    random.shuffle(self.seq)\n",
      "  File \"C:\\Users\\policast\\Programs\\Anaconda3.7\\lib\\random.py\", line 278, in shuffle\n",
      "    x[i], x[j] = x[j], x[i]\n",
      "TypeError: 'range' object does not support item assignment\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_sum_tuple (__main__.TestSum)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-41-104fd55aeb27>\", line 7, in test_sum_tuple\n",
      "    self.assertEqual(sum((1, 2, 2)), 6, \"Should be 6\")\n",
      "AssertionError: 5 != 6 : Should be 6\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.020s\n",
      "\n",
      "FAILED (failures=1, errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x19234584860>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestSequenceFunctions(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.seq = range(10)\n",
    "\n",
    "    def test_shuffle(self):\n",
    "        # make sure the shuffled sequence does not lose any elements\n",
    "        random.shuffle(self.seq)\n",
    "        self.seq.sort()\n",
    "        self.assertEqual(self.seq, range(10))\n",
    "\n",
    "        # should raise an exception for an immutable sequence\n",
    "        self.assertRaises(TypeError, random.shuffle, (1,2,3))\n",
    "\n",
    "    def test_choice(self):\n",
    "        element = random.choice(self.seq)\n",
    "        self.assertTrue(element in self.seq)\n",
    "\n",
    "    def test_sample(self):\n",
    "        with self.assertRaises(ValueError):\n",
    "            random.sample(self.seq, 20)\n",
    "        for element in random.sample(self.seq, 5):\n",
    "            self.assertTrue(element in self.seq)\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to test \n",
    "def factorial(n): \n",
    "    ''' \n",
    "    This function calculates recursively and \n",
    "    returns the factorial of a positive number. \n",
    "    Define input and expected output: \n",
    "    >>> factorial(3) \n",
    "    6 \n",
    "    >>> factorial(5) \n",
    "    120 \n",
    "    '''\n",
    "    if n <= 1: \n",
    "        return 1\n",
    "    return n * factorial(n - 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    factorial(3) \n",
      "Expecting:\n",
      "    6 \n",
      "**********************************************************************\n",
      "File \"__main__\", line 7, in factorial.factorial\n",
      "Failed example:\n",
      "    factorial(3) \n",
      "Expected:\n",
      "    6 \n",
      "Got:\n",
      "    6\n",
      "Trying:\n",
      "    factorial(5) \n",
      "Expecting:\n",
      "    120 \n",
      "**********************************************************************\n",
      "File \"__main__\", line 9, in factorial.factorial\n",
      "Failed example:\n",
      "    factorial(5) \n",
      "Expected:\n",
      "    120 \n",
      "Got:\n",
      "    120\n",
      "15 items had no tests:\n",
      "    factorial\n",
      "    factorial.TestSequenceFunctions\n",
      "    factorial.TestSequenceFunctions.setUp\n",
      "    factorial.TestSequenceFunctions.test_choice\n",
      "    factorial.TestSequenceFunctions.test_sample\n",
      "    factorial.TestSequenceFunctions.test_shuffle\n",
      "    factorial.TestSum\n",
      "    factorial.TestSum.test_sum\n",
      "    factorial.TestSum.test_sum_tuple\n",
      "    factorial.avg\n",
      "    factorial.get_stats\n",
      "    factorial.primes_list\n",
      "    factorial.primes_list_buggy\n",
      "    factorial.rev_list\n",
      "    factorial.rev_list_buggy\n",
      "**********************************************************************\n",
      "1 items had failures:\n",
      "   2 of   2 in factorial.factorial\n",
      "2 tests in 16 items.\n",
      "0 passed and 2 failed.\n",
      "***Test Failed*** 2 failures.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=2, attempted=2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctest.testmod(name ='factorial', verbose = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Practices\n",
    "\n",
    " - Fast:\n",
    "Tests should be fast so they can be run frequently\n",
    " - Independent:\n",
    "Tests should not depend on each other so they can be run in any order\n",
    " - Repeatable:\n",
    "Tests should be repeatable in any environment (e.g. production, development) or it will be an excuse not to run them\n",
    " - Self-validating:\n",
    "Tests should either pass or fail otherwise the tests become subjective\n",
    " - Timely:\n",
    "Write the tests during code development, not after the program is completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Not \n",
    "- Write entire program\n",
    "- Test entire program\n",
    "- Debug entire program\n",
    "\n",
    "instead \n",
    "\n",
    "### Do\n",
    "\n",
    "- Write a function\n",
    "- Test the function, debug the function\n",
    "- Write a function\n",
    "- Test the function, debug the function\n",
    "- *** Do integration testing ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Not \n",
    "\n",
    "- Change code\n",
    "- Remember where bug was\n",
    "- Test code\n",
    "- Forget where bug was or what change\n",
    "you made\n",
    "- Panic\n",
    "\n",
    "### Do\n",
    "\n",
    "- Branch\n",
    "- Change code\n",
    "- Write down potential bug commit messag\n",
    "- Test code\n",
    "- Diff new version with old\n",
    "version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
